# üó∫Ô∏è The Roadmap: From Files to Lakehouse

### Level 0: The Playground (In-Memory)
**Goal:** Instant SQL feedback without setup.
- **Concepts:** `duckdb.sql()`, Relations, and in-memory execution.
- **Key Learn:** Why in-memory is great for experimentation but bad for production persistence.

### Level 1: The Input (File Formats)
**Goal:** Master the "Ingestion" layer.
- **Concepts:** Reading messy CSVs, handling nested JSON, and converting them to high-performance Parquet.
- **Key Learn:** **Schema Enforcement.** Why `read_parquet` is safer and faster than `read_csv`.

### Level 2: The Logic (Output Formats)
**Goal:** Get data into the right shape for your code.
- **Concepts:** Moving data from DuckDB into Polars, Pandas, and Arrow.
- **Key Learn:** **Zero-Copy.** Moving millions of rows between engines in 0ms using Arrow.

### Level 3: The Reliability (Lakehouse Formats)
**Goal:** Solve the "Update Problem."
- **Concepts:** Implementing Delta Lake and Iceberg.
- **Key Learn:** How to `UPDATE` or `DELETE` rows in a Parquet-based world without rewriting the whole dataset.